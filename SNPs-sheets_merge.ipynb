{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some pandas opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### where are the files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m16 documents from consensus.geneious\u001b[0m*\r\n",
      "\u001b[01;32m16 documents from WT-day70 to WT-zero point.geneious\u001b[0m*\r\n",
      "\u001b[34;42mBY-day0\u001b[0m/\r\n",
      "\u001b[34;42mBY-nup133-day70\u001b[0m/\r\n",
      "\u001b[34;42mBY-WT-day70\u001b[0m/\r\n",
      "\u001b[34;42mconsensus\u001b[0m/\r\n",
      "\u001b[34;42mmapped_contigs\u001b[0m/\r\n",
      "\u001b[34;42mmapped_reads\u001b[0m/\r\n",
      "\u001b[01;32mnup mapped to wt cons.geneious\u001b[0m*\r\n",
      "\u001b[34;42mW303-cog7-day42\u001b[0m/\r\n",
      "\u001b[34;42mW303-nup133-day42\u001b[0m/\r\n",
      "\u001b[34;42mWT-day70\u001b[0m/\r\n",
      "\u001b[01;32mWT-day70.xlsx\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls /home/dizak/Pulpit/BIONAS/G148/SNPs_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W303_cog7_day42_C1_files = glob(\"/home/dizak/Pulpit/BIONAS/G148/SNPs_calling/W303-cog7-day42/C1/*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W303_cog7_day42_C2_files = glob(\"/home/dizak/Pulpit/BIONAS/G148/SNPs_calling/W303-cog7-day42/C2/*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W303_cog7_day42_C3_files = glob(\"/home/dizak/Pulpit/BIONAS/G148/SNPs_calling/W303-cog7-day42/C3/*csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get non-redundant list of genes in the inputfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_flat_value(inputfiles_list,\n",
    "                    col_name = \"CDS\"):\n",
    "    \"\"\"\n",
    "    Get flat list of desired values from list of CSV files.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    inputfiles_list: list of str\n",
    "        List of input CSV files.\n",
    "    col_name: str\n",
    "        Desired column name in the input CSV file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of desired values.\n",
    "    \"\"\"\n",
    "    values_list = []\n",
    "    for i in inputfiles_list:\n",
    "        df = pd.read_csv(i)\n",
    "        if len(df) == 0:\n",
    "            pass\n",
    "        elif col_name not in df.columns:\n",
    "            pass\n",
    "        else:\n",
    "            values_list.append(df[col_name].dropna().drop_duplicates().tolist())\n",
    "    return list(itertools.chain.from_iterable(values_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get values from input files by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_by_key(inputfiles_list,\n",
    "                key):\n",
    "    \"\"\"\n",
    "    Get pandas.DataFrame selected by a given key from list of CSV files.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    inputfiles_list: list of str\n",
    "        List of input CSV files.\n",
    "    key: str, int, float, bool\n",
    "        Key used as query against rows in the CSV files.\n",
    "    value_col: str\n",
    "        Column name which holds values to be returned.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict of lists of desired values if pandas.Dataframe not empty\n",
    "    None if pandas.DataFrame empty\n",
    "    \"\"\"\n",
    "    values_list = []\n",
    "    for i in inputfiles_list:\n",
    "        filename = \"\".join(i.split(\"/\")[-1].split(\".\")[:-1])\n",
    "        df = pd.read_csv(i)\n",
    "        if len(df) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if isinstance(key, str) == True:\n",
    "                df_dtype_sel = df.select_dtypes(include=[\"object\"])\n",
    "            elif isinstance(key, int) == True:\n",
    "                df_dtype_sel = df.select_dtypes(include=[\"int\"])\n",
    "            elif isinstance(key, float) == True:\n",
    "                df_dtype_sel = df.select_dtypes(include=[\"float\"])\n",
    "            elif isinstance(key, bool) == True:\n",
    "                df_dtype_sel = df.select_dtypes(include=[\"bool\"])\n",
    "            else:\n",
    "                raise ValueError(\"key must str, int, float or bool dtype\")\n",
    "            for col in df_dtype_sel.columns:\n",
    "                df_sel = df[df_dtype_sel[col] == key]\n",
    "                if len(df_sel) > 0:\n",
    "                    return {\"dataframe\": df_sel,\n",
    "                            \"filename\": filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get whole set of pandas.DataFrames selections in one dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dfs_set(key_list,\n",
    "                files_list,\n",
    "                vals=[\"Minimum\",\n",
    "                      \"Maximum\",\n",
    "                      \"Change\"],\n",
    "                df_key=\"dataframe\",\n",
    "                index_by_key=True):\n",
    "    \"\"\"\n",
    "    Get desired values in pandas.Dataframe gathered in dict by\n",
    "    the list of keys.\n",
    "    \"\"\"\n",
    "    out_dict = {}\n",
    "    for i in key_list:\n",
    "        key_vals = find_by_key(files_list,\n",
    "                              key=i)[df_key]\n",
    "        out_dict[i] = key_vals[vals]\n",
    "    if index_by_key is True:\n",
    "        for i in out_dict:\n",
    "            out_dict[i].index = [i] * len(out_dict[i])\n",
    "    else:\n",
    "        pass\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge any given number of dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge any given number of dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dfs(dfs,\n",
    "              sort_cols=[\"Minimum\",\n",
    "                         \"Maximum\"]):\n",
    "    \"\"\"\n",
    "    Merge any number of pandas.DataFrame into one.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    dfs: list\n",
    "        list of pandas.DataFrames to merge.\n",
    "    sort_cols: list, None\n",
    "        list of col names to sort the final\n",
    "        pandas.DataFrame by. No sorting if None.\n",
    "    \"\"\"\n",
    "    df = reduce(lambda df1, df2: pd.merge(left=df1,\n",
    "                                          right=df2,\n",
    "                                          how=\"outer\"),\n",
    "                dfs)\n",
    "    if sort_cols is not None:\n",
    "        df.sort(columns=sort_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's find out which CDS are present in all the files one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W303_cog7_day42_C1_CDSs = find_flat_value(W303_cog7_day42_C1_files)\n",
    "W303_cog7_day42_C2_CDSs = find_flat_value(W303_cog7_day42_C2_files)\n",
    "W303_cog7_day42_C3_CDSs = find_flat_value(W303_cog7_day42_C3_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's gather some info about each of the CDS from each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W303_cog7_day42_C1_dfs = get_dfs_set(W303_cog7_day42_C1_CDSs, W303_cog7_day42_C1_files)\n",
    "W303_cog7_day42_C2_dfs = get_dfs_set(W303_cog7_day42_C2_CDSs, W303_cog7_day42_C2_files)\n",
    "W303_cog7_day42_C3_dfs = get_dfs_set(W303_cog7_day42_C3_CDSs, W303_cog7_day42_C3_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### which CDSs are common for all 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W303_cog7_day42_comm_CDS = reduce(lambda x, y: [i for i in x if i in y],\n",
    "                                  [W303_cog7_day42_C1_CDSs,\n",
    "                                   W303_cog7_day42_C2_CDSs,\n",
    "                                   W303_cog7_day42_C3_CDSs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
